{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Downfalls\n",
    "\n",
    "- Dataset too small\n",
    "- Dataset imbalanced (95% non stroke - 5% stroke) and trying to predict stroke...\n",
    "- Try to increase Recall but lose precision more than desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data getting, cleaning, and exploring\n",
    "import wrangle as w\n",
    "import explore as ex\n",
    "\n",
    "# Python without these is hard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Regression Modeling\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Classification Modeling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = w.wrangle_stroke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = w.train_validate_test_split(df, 'stroke', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['stroke'])\n",
    "y_train = train.stroke\n",
    "\n",
    "X_validate = validate.drop(columns=['stroke'])\n",
    "y_validate = validate.stroke\n",
    "\n",
    "X_test = test.drop(columns=['stroke'])\n",
    "y_test = test.stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X_train.loc[:,df.dtypes == \"object\"].columns\n",
    "num_cols = X_train.loc[:,df.dtypes != \"object\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'hypertension', 'heart_disease', 'ever_married',\n",
       "       'avg_glucose_level', 'bmi', 'rural_residence', 'urban_residence',\n",
       "       'is_female', 'is_male', 'current_smoker', 'age_bin', 'gluc_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_cols),\n",
    "        ('cat', cat_pipeline, cat_cols)\n",
    "    ])\n",
    "    \n",
    "\n",
    "X_train = full_pipeline.fit_transform(X_train, y_train)\n",
    "X_test = full_pipeline.fit_transform(X_test)\n",
    "X_validate = full_pipeline.fit_transform(X_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# imbalanced-learn \n",
    "    pip install imbalanced-learn\n",
    "    \n",
    "    a python package offering a number of re-sampling techniques commonly used in datasets showing strong between-class imbalance. \n",
    "    It is compatible with scikit-learn and is part of scikit-learn-contrib projects.\n",
    "\n",
    "## Oversampling and undersampling \n",
    "    techniques used to adjust the class distribution of a data set (i.e. the ratio between the different classes/categories represented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see only 5% of data show patients who had a stroke. It is a clear inbalance which will not allow\n",
    "# model to learn properly. To avoid that I will try a couple of methods(undersampling and oversampling)\n",
    "# to eliminate the problem.\n",
    "# Let's check wich method works the best with RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler, AllKNN, NeighbourhoodCleaningRule\n",
    "\n",
    "equalizers = [\n",
    "    SMOTE(),\n",
    "    BorderlineSMOTE(),\n",
    "    ADASYN(),\n",
    "    SVMSMOTE(),\n",
    "    NearMiss(),\n",
    "    RandomUnderSampler(),\n",
    "    AllKNN(),\n",
    "    NeighbourhoodCleaningRule()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "def train_and_evaluate(model, train, train_y, test, test_y, eq=None, train_model=True, threashold=0.5):\n",
    "    if train_model:\n",
    "        model.fit(train, train_y)\n",
    "    \n",
    "    results = model.predict_proba(test)\n",
    "    \n",
    "    proba = results[:,1]\n",
    "    results = (results[:,1] > threashold).astype(int)\n",
    "    \n",
    "    print('/'*80)\n",
    "    print(model)\n",
    "    if eq != None:\n",
    "        print(eq)\n",
    "    print()\n",
    "    print('confusion_matrix')\n",
    "    print(confusion_matrix(test_y, results))\n",
    "    print('roc_auc')\n",
    "    print(roc_auc_score(test_y, proba))\n",
    "    print(classification_report(test_y, results))\n",
    "    \n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "SMOTE()\n",
      "\n",
      "confusion_matrix\n",
      "[[698 274]\n",
      " [ 31  19]]\n",
      "roc_auc\n",
      "0.6505246913580247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.72      0.82       972\n",
      "           1       0.06      0.38      0.11        50\n",
      "\n",
      "    accuracy                           0.70      1022\n",
      "   macro avg       0.51      0.55      0.47      1022\n",
      "weighted avg       0.91      0.70      0.79      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "BorderlineSMOTE()\n",
      "\n",
      "confusion_matrix\n",
      "[[839 133]\n",
      " [ 38  12]]\n",
      "roc_auc\n",
      "0.7185288065843621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       972\n",
      "           1       0.08      0.24      0.12        50\n",
      "\n",
      "    accuracy                           0.83      1022\n",
      "   macro avg       0.52      0.55      0.52      1022\n",
      "weighted avg       0.91      0.83      0.87      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "ADASYN()\n",
      "\n",
      "confusion_matrix\n",
      "[[734 238]\n",
      " [ 38  12]]\n",
      "roc_auc\n",
      "0.6269650205761317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.84       972\n",
      "           1       0.05      0.24      0.08        50\n",
      "\n",
      "    accuracy                           0.73      1022\n",
      "   macro avg       0.50      0.50      0.46      1022\n",
      "weighted avg       0.91      0.73      0.80      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "SVMSMOTE()\n",
      "\n",
      "confusion_matrix\n",
      "[[896  76]\n",
      " [ 42   8]]\n",
      "roc_auc\n",
      "0.7222530864197532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       972\n",
      "           1       0.10      0.16      0.12        50\n",
      "\n",
      "    accuracy                           0.88      1022\n",
      "   macro avg       0.53      0.54      0.53      1022\n",
      "weighted avg       0.91      0.88      0.90      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "NearMiss()\n",
      "\n",
      "confusion_matrix\n",
      "[[253 719]\n",
      " [  9  41]]\n",
      "roc_auc\n",
      "0.6526131687242799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.26      0.41       972\n",
      "           1       0.05      0.82      0.10        50\n",
      "\n",
      "    accuracy                           0.29      1022\n",
      "   macro avg       0.51      0.54      0.26      1022\n",
      "weighted avg       0.92      0.29      0.39      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "RandomUnderSampler()\n",
      "\n",
      "confusion_matrix\n",
      "[[670 302]\n",
      " [ 11  39]]\n",
      "roc_auc\n",
      "0.8052160493827162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81       972\n",
      "           1       0.11      0.78      0.20        50\n",
      "\n",
      "    accuracy                           0.69      1022\n",
      "   macro avg       0.55      0.73      0.51      1022\n",
      "weighted avg       0.94      0.69      0.78      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "AllKNN()\n",
      "\n",
      "confusion_matrix\n",
      "[[941  31]\n",
      " [ 42   8]]\n",
      "roc_auc\n",
      "0.7943930041152263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       972\n",
      "           1       0.21      0.16      0.18        50\n",
      "\n",
      "    accuracy                           0.93      1022\n",
      "   macro avg       0.58      0.56      0.57      1022\n",
      "weighted avg       0.92      0.93      0.92      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier(random_state=1234)\n",
      "NeighbourhoodCleaningRule()\n",
      "\n",
      "confusion_matrix\n",
      "[[958  14]\n",
      " [ 46   4]]\n",
      "roc_auc\n",
      "0.7939300411522634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       972\n",
      "           1       0.22      0.08      0.12        50\n",
      "\n",
      "    accuracy                           0.94      1022\n",
      "   macro avg       0.59      0.53      0.54      1022\n",
      "weighted avg       0.92      0.94      0.93      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eq in equalizers:\n",
    "    model = RandomForestClassifier(random_state=1234)\n",
    "    X_train_eq, y_train_eq = eq.fit_resample(X_train, y_train.ravel())\n",
    "    train_and_evaluate(model, X_train_eq, y_train_eq, X_test, y_test, eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we can see randomundersampler seems to be working the best(it maximize the recall for stoke) \n",
    "\n",
    "eq = RandomUnderSampler()\n",
    "X_train, y_train = eq.fit_resample(X_train, y_train.ravel())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The small size of the dataset creates an issue once we run our Random Under Sampler\n",
    "### Data set dropped from 5k to 278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly go through couple models and pick 2~3 the best of them to try improve the results with \n",
    "# various hyperparameters. We are going to try to maximize roc_auc score\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (AdaBoostClassifier(), 'AdaBoost'),\n",
    "    (RandomForestClassifier(), 'RandomForest'),\n",
    "    (ExtraTreesClassifier(), 'ExtraTreesClassifier'),\n",
    "    (LogisticRegression(), 'LogisticRegression'),\n",
    "    (KNeighborsClassifier(), 'KNeighbors'),\n",
    "    (SVC(probability=True), 'SVC'),\n",
    "]\n",
    "\n",
    "def print_scores(scores, model_name):\n",
    "    print(model_name)\n",
    "    print()\n",
    "    print(scores)\n",
    "    print(\"mean: {}\".format(scores.mean()))\n",
    "    print(\"std: {}\".format(scores.std()))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////////////////////////\n",
      "AdaBoostClassifier()\n",
      "\n",
      "confusion_matrix\n",
      "[[680 292]\n",
      " [ 12  38]]\n",
      "roc_auc\n",
      "0.8116666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82       972\n",
      "           1       0.12      0.76      0.20        50\n",
      "\n",
      "    accuracy                           0.70      1022\n",
      "   macro avg       0.55      0.73      0.51      1022\n",
      "weighted avg       0.94      0.70      0.79      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "RandomForestClassifier()\n",
      "\n",
      "confusion_matrix\n",
      "[[684 288]\n",
      " [ 11  39]]\n",
      "roc_auc\n",
      "0.8225925925925927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.82       972\n",
      "           1       0.12      0.78      0.21        50\n",
      "\n",
      "    accuracy                           0.71      1022\n",
      "   macro avg       0.55      0.74      0.51      1022\n",
      "weighted avg       0.94      0.71      0.79      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "ExtraTreesClassifier()\n",
      "\n",
      "confusion_matrix\n",
      "[[661 311]\n",
      " [ 16  34]]\n",
      "roc_auc\n",
      "0.7808847736625514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.68      0.80       972\n",
      "           1       0.10      0.68      0.17        50\n",
      "\n",
      "    accuracy                           0.68      1022\n",
      "   macro avg       0.54      0.68      0.49      1022\n",
      "weighted avg       0.93      0.68      0.77      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "LogisticRegression()\n",
      "\n",
      "confusion_matrix\n",
      "[[702 270]\n",
      " [ 11  39]]\n",
      "roc_auc\n",
      "0.8319341563786008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83       972\n",
      "           1       0.13      0.78      0.22        50\n",
      "\n",
      "    accuracy                           0.73      1022\n",
      "   macro avg       0.56      0.75      0.53      1022\n",
      "weighted avg       0.94      0.73      0.80      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "KNeighborsClassifier()\n",
      "\n",
      "confusion_matrix\n",
      "[[659 313]\n",
      " [ 14  36]]\n",
      "roc_auc\n",
      "0.7407407407407407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.68      0.80       972\n",
      "           1       0.10      0.72      0.18        50\n",
      "\n",
      "    accuracy                           0.68      1022\n",
      "   macro avg       0.54      0.70      0.49      1022\n",
      "weighted avg       0.94      0.68      0.77      1022\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "SVC(probability=True)\n",
      "\n",
      "confusion_matrix\n",
      "[[698 274]\n",
      " [ 12  38]]\n",
      "roc_auc\n",
      "0.7941358024691358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83       972\n",
      "           1       0.12      0.76      0.21        50\n",
      "\n",
      "    accuracy                           0.72      1022\n",
      "   macro avg       0.55      0.74      0.52      1022\n",
      "weighted avg       0.94      0.72      0.80      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, name in models:\n",
    "    train_and_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
